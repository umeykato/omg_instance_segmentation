{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T04:54:35.458415Z",
     "start_time": "2018-05-27T04:54:35.299306Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T04:54:35.605623Z",
     "start_time": "2018-05-27T04:54:35.459565Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from model import UNet\n",
    "from dataset import SSSDataset\n",
    "from loss import DiscriminativeLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T04:54:35.608184Z",
     "start_time": "2018-05-27T04:54:35.606670Z"
    }
   },
   "outputs": [],
   "source": [
    "n_sticks = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T04:54:36.974833Z",
     "start_time": "2018-05-27T04:54:35.609077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = UNet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T04:54:36.978309Z",
     "start_time": "2018-05-27T04:54:36.975999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset for train\n",
    "train_dataset = SSSDataset(train=True, n_sticks=n_sticks)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1,\n",
    "                              shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T04:54:36.981864Z",
     "start_time": "2018-05-27T04:54:36.979448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "criterion_disc = DiscriminativeLoss(delta_var=0.5,\n",
    "                                    delta_dist=1.5,\n",
    "                                    norm=2,\n",
    "                                    usegpu=True).cuda()\n",
    "criterion_ce = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T04:54:36.986508Z",
     "start_time": "2018-05-27T04:54:36.983106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "parameters = model.parameters()\n",
    "optimizer = optim.SGD(parameters, lr=0.01, momentum=0.9, weight_decay=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min',\n",
    "                                                 factor=0.1,\n",
    "                                                 patience=10,\n",
    "                                                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T04:54:38.403441Z",
     "start_time": "2018-05-27T04:54:36.987711Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 6 \n",
      "  289.1282   340.1148   372.1285   317.8081   372.1449   286.3738   530.7367\n",
      " -324.3894  -499.7675  -411.0128  -289.9552  -401.6709  -369.9888  -514.5149\n",
      " -289.9343  -518.9856  -300.0668  -245.7392  -263.9046  -545.4254  -468.9028\n",
      " -295.9814  -463.8456  -353.8270  -269.4973  -300.6821  -461.2397  -454.7359\n",
      "  286.6226   582.5879   208.6590   268.9242   293.7649   584.9517   447.5388\n",
      " -328.2320  -732.3148  -453.0490  -330.2997  -402.1884  -509.5753  -576.3776\n",
      "  -35.4079   -62.8584   -88.7989   -29.6020   -67.4757   -95.4357  -137.2250\n",
      "  247.6983   400.9331   247.5770   260.8599   378.2213   427.8092   480.2264\n",
      " -439.2777  -650.9365  -437.8488  -394.9053  -424.3885  -614.9483  -764.9960\n",
      " -370.1022  -639.5310  -417.9650  -389.3400  -487.3299  -735.7640  -772.9658\n",
      "  216.9915   455.1708   177.0734   215.8366   259.1003   436.7773   361.8412\n",
      " -261.6340  -381.2768  -250.6012  -213.5548  -189.0978  -283.6579  -329.3127\n",
      "   78.1148   176.4632   -18.9923   100.9537   112.0676   244.8641    21.4845\n",
      "  583.3524   975.1033   584.1496   576.1080   747.3795  1068.3241   983.1210\n",
      " -275.4825  -558.2429  -198.4647  -255.9228  -267.4146  -563.5082  -376.5680\n",
      "  567.0447   837.7599   462.3499   475.5333   459.6587   776.6309   757.5245\n",
      "\n",
      "Columns 7 to 7 \n",
      "  336.7732\n",
      " -313.9506\n",
      " -336.0572\n",
      " -340.2920\n",
      "  403.5618\n",
      " -410.6164\n",
      "   25.7694\n",
      "  280.6394\n",
      " -462.4659\n",
      " -392.7894\n",
      "  348.7897\n",
      " -335.6644\n",
      "   97.1245\n",
      "  659.1868\n",
      " -353.3697\n",
      "  667.8414\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1032  1576   965  1012  1173  1455  1622  1312\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "Variable containing:\n",
      " 409.2423  271.4349  268.6409  340.2598  588.6881  293.8704  368.3122  241.3531\n",
      "-408.5717 -298.4302 -413.7716 -215.5092 -636.2034 -270.3587 -312.5568 -397.2877\n",
      "-397.9055 -346.3808 -354.2163 -247.4413 -425.9612 -369.7806 -230.3764 -418.5474\n",
      "-449.8148 -315.1438 -360.2395 -297.6144 -576.9904 -302.5469 -322.2790 -209.8101\n",
      " 386.4068  424.1185  297.0079  369.2881  311.6570  408.9666  312.7592  379.6805\n",
      "-479.1748 -383.9897 -418.9306 -351.9043 -545.4485 -390.2455 -381.7845 -388.8459\n",
      " -63.6048   39.0318  -84.0221   15.0764 -101.7657  118.6460  -27.0034  -44.1771\n",
      " 298.5755  373.6730  366.4399  236.3862  354.6580  285.1310  455.6268  394.2419\n",
      "-507.8050 -455.1279 -471.4676 -443.0092 -626.3418 -430.7410 -488.9922 -457.6764\n",
      "-549.6446 -531.0175 -610.7357 -378.4197 -703.9569 -312.8183 -656.4272 -575.0991\n",
      " 222.9930  435.0201  259.4811  265.2174  166.4590  405.4453  248.4357  434.4764\n",
      "-270.3484 -231.0418 -140.3027 -240.9465 -315.9141 -344.5427  -76.7923 -242.8969\n",
      " 119.1526  141.8616   77.1631  174.4301   20.7386  140.3155  230.2329  114.1289\n",
      " 845.4072  649.8361  733.3340  526.5343  954.7447  665.6940  686.4523  781.6068\n",
      "-412.3697 -352.0771 -290.5378 -373.2258 -375.8748 -390.3143 -326.1312 -231.4324\n",
      " 668.8957  673.9358  511.1834  457.3672  867.0651  697.1553  572.6161  563.7594\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1305  1436  1059   940  1540  1510  1350  1474\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "Variable containing:\n",
      " 281.9730  293.4688  414.5070  275.5848  248.4205  452.3902  359.1868  256.2353\n",
      "-328.3963 -346.1785 -449.1874 -428.1037 -209.2257 -529.5764 -359.9918 -375.2055\n",
      "-400.2945 -359.9216 -350.8194 -277.3098 -231.1087 -405.3925 -358.4232 -364.9367\n",
      "-313.8652 -337.9318 -305.3969 -308.3826 -225.4667 -469.6595 -401.9268 -311.9370\n",
      " 433.7725  330.1066  445.4818  267.7790  335.5507  326.1640  423.1191  352.4663\n",
      "-422.6225 -351.6563 -476.3553 -453.9094 -269.7074 -468.1666 -473.9159 -416.9404\n",
      " -27.9866  -91.0425 -174.2749  -20.4537   96.2077  -45.5902   14.7565   54.8991\n",
      " 438.9313  299.5232  533.2908  409.4468  291.7613  398.1721  466.0711  319.6075\n",
      "-445.0122 -493.9654 -590.2106 -469.3104 -298.5044 -519.6763 -548.6896 -473.5989\n",
      "-606.0520 -547.3270 -787.0291 -569.6391 -367.2276 -573.1931 -687.2555 -476.9058\n",
      " 479.5430  264.8711  369.7138  269.1085  415.1580  343.3722  465.9128  341.2091\n",
      "-215.4260 -180.4686 -173.9163 -159.6589 -174.6881 -266.6940 -190.6203 -253.4855\n",
      " 179.6416  137.4912  140.0151   80.7854   82.2882   13.8857  187.4063  160.1486\n",
      " 822.5190  738.1016  970.1724  635.5801  451.1035  882.1839  756.7881  646.8171\n",
      "-293.9847 -364.9969 -304.6176 -272.5314 -242.8511 -304.0365 -407.1937 -374.7452\n",
      " 656.3240  481.3630  537.2772  570.7625  393.7271  687.7030  684.8897  680.6921\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1560  1017  1518  1310   917  1368  1596  1560\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "Variable containing:\n",
      " 402.6701  266.5646  316.6914  456.5403  272.5951  220.7489  292.7913  314.0873\n",
      "-405.1501 -364.8048 -483.9696 -461.6466 -368.3601 -285.9553 -322.4732 -350.9079\n",
      "-337.0723 -355.3226 -301.7422 -280.5248 -359.6053 -349.0992 -312.3953 -420.7356\n",
      "-368.9241 -355.2489 -321.1635 -433.9676 -240.0507 -332.3951 -284.6743 -344.5226\n",
      " 346.2281  327.4564  298.5981  208.4753  431.4933  428.6854  352.6375  453.7609\n",
      "-443.0225 -386.6710 -517.5626 -421.5477 -410.6113 -432.3253 -368.2663 -466.4486\n",
      " -36.7924  -67.2156   25.2972  -96.7840  -99.8696   18.6085   27.8838  -26.1565\n",
      " 430.8019  317.8532  364.5961  231.0838  398.3574  404.1917  310.5977  423.4750\n",
      "-548.8581 -473.8661 -446.3324 -439.4885 -461.0626 -437.6225 -429.2960 -508.0813\n",
      "-617.7221 -574.9977 -467.6166 -475.2136 -634.5245 -564.1089 -335.3262 -661.4326\n",
      " 323.1218  274.5432  316.7056   73.7112  362.9532  413.0498  343.9171  449.3026\n",
      "-235.7328 -152.6599 -222.0227 -234.1476 -189.1552 -126.0245 -337.6656 -184.3729\n",
      " 175.1055  148.4815   53.1551   19.1292  181.5627  177.0831  166.2039  238.1882\n",
      " 780.5581  728.5286  646.9086  692.4493  783.7507  723.2825  659.1432  888.5463\n",
      "-341.2694 -379.5885 -317.8961 -270.4868 -273.1146 -395.8284 -323.5071 -420.1696\n",
      " 663.9738  466.6631  566.6528  571.8120  521.2228  589.7358  644.3553  620.0374\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1499  1008  1341  1028  1458  1312  1374  1560\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n",
      "Variable containing:\n",
      "  66.1997   12.6226  110.4563   73.4197  362.3751  348.2762   19.1753  264.7376\n",
      "-219.4373 -212.5518 -372.4997 -287.1280 -605.3279 -894.6602 -296.7275 -500.3760\n",
      "-120.0166  -94.5698 -122.3221 -128.5439 -358.4308 -321.1115 -147.6702 -359.8292\n",
      " -20.3077   29.5684   -7.5729    9.0071 -176.1163 -149.1725   71.7120 -176.9236\n",
      " 117.5428  132.6470   12.4700  167.8290  414.9622   84.2779  277.6964  482.8192\n",
      "-212.2605 -230.7278 -344.4980 -326.8186 -592.6537 -796.1100 -346.4199 -508.9691\n",
      "  82.3295  139.1710   70.5605  107.5213   58.1329   92.8228  257.1546   60.8530\n",
      " 189.1274  220.3142  192.9192  240.0956  519.0226  348.8872  278.1833  557.7941\n",
      " -69.8145    3.7917  -48.1120  -71.2364 -405.1439 -221.4685  -26.1307 -429.0660\n",
      "-180.4503 -176.3605 -179.3164 -233.7958 -608.5259 -404.3594 -196.3462 -678.7403\n",
      " 187.8112  227.8522  127.7799  213.3027  421.9694  206.6698  338.9242  466.4064\n",
      " -71.2426  -38.4677  -86.8754  -77.2747 -268.3598 -223.3412 -155.5894 -190.3151\n",
      "  42.1442   72.1882  -60.9512   61.1789  130.8593 -216.4171  167.1672  242.8096\n",
      " 256.1873  199.4806  233.5907  284.8947  935.1780  670.4614  306.3567  874.8325\n",
      " -99.6639  -96.1999  -71.1462 -135.1774 -313.4392 -150.7337 -214.0831 -330.6530\n",
      " 182.2773  156.3057  126.4781  243.8121  630.5215  395.0829  347.8509  635.3015\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "  622   966   640   977  1472  1454  1556  1364\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 6 \n",
      "  126.7444   167.6115  1203.0079   501.2605   112.0944    40.7736    48.7775\n",
      " -469.2883  -519.5766 -1680.6202  -791.6295  -333.2549  -265.5423  -319.6600\n",
      " -179.1559  -156.4423  -416.7061  -292.2967  -283.5823  -139.0759  -160.0377\n",
      "    1.6862   -34.7412 -1100.3831  -299.7593   -58.5417    24.4226    46.3422\n",
      "  109.5329   111.7032   225.8566   211.3981   371.1170   231.4277   265.3785\n",
      " -449.6679  -445.8786 -1057.3645  -652.3430  -406.5523  -322.2420  -381.9030\n",
      "  115.0957    20.5500  -638.9155   -87.5234   159.9926   223.0737   282.3920\n",
      "  283.9989   346.9993   883.4571   452.0106   377.5178   299.3874   362.3686\n",
      "  -76.1643  -173.9169 -1445.6677  -466.0665  -194.4918   -34.4844   -32.0445\n",
      " -287.1700  -362.5647 -1237.3068  -502.7355  -398.0221  -218.0289  -233.3879\n",
      "  198.7704   169.0152   -14.0569   227.0670   431.5076   329.5919   370.7769\n",
      " -120.9108   -84.8895  -408.5777  -313.2827  -184.1255  -108.9583  -134.7447\n",
      "  -33.8010   -59.3429  -255.2891  -141.8672   182.9088   173.3136   189.7610\n",
      "  396.4198   510.7225  1960.9419   879.7864   539.0634   257.7951   303.0796\n",
      " -135.0858  -130.8239  -446.5110  -132.7968  -213.3748  -164.7019  -193.8338\n",
      "  225.7374   244.4375  1252.7491   618.5338   485.3293   310.6929   381.1803\n",
      "\n",
      "Columns 7 to 7 \n",
      "   29.3886\n",
      " -284.5024\n",
      " -196.5271\n",
      "   83.3779\n",
      "  375.2077\n",
      " -365.6467\n",
      "  237.6717\n",
      "  355.6975\n",
      "  -66.7084\n",
      " -345.0866\n",
      "  375.7259\n",
      " -195.1802\n",
      "  136.1466\n",
      "  460.6882\n",
      " -208.7832\n",
      "  402.1959\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1075   996  1291  1402  1429  1382  1640  1544\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 6 \n",
      "   66.5495   551.3003   395.2346    67.1615   953.3110  2191.9919   618.0050\n",
      " -269.9544  -682.7641  -638.6856  -205.6021 -1273.7715 -2993.4099  -838.1449\n",
      " -157.8288  -409.0286  -382.0423  -122.7659  -368.3439  -695.8494  -293.6465\n",
      "  -41.0068  -357.5225  -199.5677   -20.0697  -796.1475 -1854.4318  -421.0518\n",
      "  236.4424   661.4338   402.5151   175.3716   424.7849   228.6923   213.6303\n",
      " -377.7785  -678.3516  -591.6092  -273.0760  -902.9489 -1906.8733  -677.9766\n",
      "  190.5621   -55.1956   100.3701   172.2949  -483.1455 -1046.3217  -107.9169\n",
      "  264.0948   777.8614   538.5992   158.5527   781.9866  1352.4048   467.1620\n",
      "  -52.6827  -793.1694  -432.2329   -51.0599 -1200.2020 -2447.5210  -618.3732\n",
      " -164.8856 -1010.1318  -642.6560   -99.0670 -1049.8734 -2022.3252  -602.7796\n",
      "  296.8808   453.1460   427.4627   198.2273   149.8931  -185.2719   127.3716\n",
      " -144.6214  -218.1165  -248.9154  -115.9787  -402.2584  -746.3456  -298.0943\n",
      "  137.0236   302.1672   117.4432   103.9317   -95.0297  -785.0571  -155.9597\n",
      "  234.7310  1357.4467   976.4904   167.6089  1641.8236  3500.8862  1020.8865\n",
      " -156.3075  -544.2186  -326.2063  -158.7108  -421.3007  -796.4803  -268.5898\n",
      "  337.5385   718.6711   620.3919   257.9244  1172.4316  1740.2421   621.9801\n",
      "\n",
      "Columns 7 to 7 \n",
      "  137.7222\n",
      " -363.9178\n",
      " -149.5919\n",
      "   10.9279\n",
      "  211.9070\n",
      " -349.9210\n",
      "  155.4987\n",
      "  369.1027\n",
      " -108.8778\n",
      " -375.8740\n",
      "  230.9496\n",
      "  -46.4982\n",
      "  105.0035\n",
      "  459.1027\n",
      " -154.1187\n",
      "  281.5094\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1308  1299  1441   973  1420  1375   936  1328\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 6 \n",
      "  108.1161    33.4124    53.1949    96.0089    25.6921    50.5337  1015.4112\n",
      " -455.2996  -302.6652  -234.0407  -460.2369  -312.9727  -577.2152 -1343.9883\n",
      " -159.5254  -182.5792  -246.4948  -178.1176  -194.9473  -189.6819  -388.1635\n",
      "   -1.3933    44.8128   -25.5069     0.4115    82.3329    42.3043  -850.6345\n",
      "  165.0379   251.0815   339.8875   153.5143   293.9583   185.2708   297.6882\n",
      " -396.3014  -321.6101  -320.7371  -404.4844  -358.9630  -489.9623  -923.1599\n",
      "   65.6252   209.2872   124.5875   139.3359   185.1052    80.8100  -480.6425\n",
      "  357.5629   277.7225   296.2765   273.0824   346.3208   506.6499   743.0521\n",
      " -123.8757   -24.7563  -128.3241   -78.3522   -71.5014  -108.8478 -1171.9712\n",
      " -373.9196  -246.8519  -315.8327  -268.0560  -335.3065  -531.6476  -971.3376\n",
      "  227.9949   323.9296   387.8271   235.4410   384.0675   314.5512    96.7228\n",
      "  -57.2700  -116.4531  -182.5129  -126.7536  -179.4929    23.4945  -429.3857\n",
      "  -24.3432   112.2847   147.7592    27.1557   137.1425    51.5170  -165.5799\n",
      "  488.2042   374.5265   431.7276   424.8514   412.0371   605.7632  1637.9781\n",
      " -170.6922  -165.0128  -156.0409  -136.4018  -160.6164  -206.3562  -351.1582\n",
      "  229.4970   334.7411   437.8344   304.1106   370.6489   227.1977  1160.3031\n",
      "\n",
      "Columns 7 to 7 \n",
      "   43.3962\n",
      " -242.8829\n",
      " -128.2901\n",
      "   39.1246\n",
      "  229.6136\n",
      " -311.9753\n",
      "  212.6604\n",
      "  241.1169\n",
      "  -32.0295\n",
      " -161.6524\n",
      "  332.1324\n",
      " -139.5968\n",
      "  150.5715\n",
      "  207.5523\n",
      " -163.0100\n",
      "  269.6169\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "  987  1380  1268  1368  1376  1428  1638  1256\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 6 \n",
      "  438.9550  1377.1028  1572.6779   112.7945   211.6793   162.0668   649.8199\n",
      " -630.5518 -2589.1506 -2933.7253   -34.5929  -414.3949  -226.3064 -1042.4166\n",
      " -126.4327  -641.5596  -743.9536  -202.2277  -140.6494  -281.8228  -337.2015\n",
      " -397.9798  -888.5202 -1066.7419  -124.9168  -120.5751  -221.4184  -445.2255\n",
      "  220.3957  -503.2359  -660.0302   429.4461   -15.2550   556.6344  -379.0162\n",
      " -554.0085 -1492.8199 -1584.6968  -303.8248  -447.7265  -477.0030  -808.8481\n",
      " -238.5503  -521.5760  -617.5172   260.1634    81.5956    20.5767   -25.1520\n",
      "  415.0131   666.1862   734.2755    38.9789   126.9678   403.4213    91.0016\n",
      " -575.9492 -1075.5870 -1225.9556  -223.9177  -100.7590  -420.3942  -198.8433\n",
      " -801.9533 -1133.1392 -1208.0857    66.6105  -168.2590  -580.8151  -145.6729\n",
      "  112.3091  -356.7528  -454.0132   213.5525    83.4890   364.9939   -85.3909\n",
      "  109.5673  -757.5605  -898.1311  -294.8457   -88.2081  -136.3251  -382.5033\n",
      "  267.8368  -922.8942 -1117.2452   277.9872    40.8026   478.2816  -379.8450\n",
      "  911.4261  1764.2286  1904.4650   288.9913   294.6585   610.8362   475.8922\n",
      " -501.1331  -217.9825  -139.3423  -406.0387   -89.7510  -409.9415   280.3599\n",
      "  308.9392   648.4282   760.6719   557.3189   183.2384   602.5652   355.5699\n",
      "\n",
      "Columns 7 to 7 \n",
      "   87.2385\n",
      "  -14.2223\n",
      " -193.6806\n",
      " -120.6797\n",
      "  382.4305\n",
      " -293.4441\n",
      "  259.7744\n",
      "  -13.2136\n",
      " -170.7514\n",
      "  116.7921\n",
      "  176.9089\n",
      " -272.8739\n",
      "  259.4479\n",
      "  216.4415\n",
      " -371.9855\n",
      "  503.8936\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1243  1519  1572  1361  1097  1596  1568  1368\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 6 \n",
      "  220.1316   428.1273   155.8124   458.2673   922.3495   118.0705   165.1310\n",
      " -340.8114  -699.8049  -371.3318  -753.0277 -1732.1859  -147.9253  -320.1172\n",
      " -202.2285  -308.9430  -148.3503  -238.2625  -378.6428  -213.3236  -194.0276\n",
      " -151.3574  -556.2994  -144.1103  -481.8477  -452.5981  -158.0628  -198.9085\n",
      "  268.9319   711.5881   199.0221   587.3361   -59.0904   394.9923   311.9024\n",
      " -432.5015  -781.9467  -378.0566  -772.1688 -1118.9590  -370.0194  -425.3394\n",
      "  165.2034  -480.4439    -9.3376  -342.6587  -360.3633   211.8718   -28.1053\n",
      "  166.0946   951.2319   263.7419   756.3749   614.8309    95.0180   273.3443\n",
      " -271.3129  -970.7145  -239.0652  -865.9713  -831.4252  -252.9559  -269.1211\n",
      " -140.8863 -1734.9844  -421.7360 -1454.1974 -1129.9799   -30.7137  -451.5963\n",
      "  176.3748   513.5516   181.3418   356.6620   -66.8913   178.2903   226.2434\n",
      " -222.8664   322.5204     2.8372   274.0015  -217.4876  -246.7581   -53.9704\n",
      "  139.6631   608.7243   185.1724   453.6058  -478.0142   231.8396   348.3620\n",
      "  451.8958  1410.0706   514.6161  1314.9685  1675.7773   329.2793   598.9525\n",
      " -342.1521  -685.4272  -282.9209  -733.6246  -507.4135  -393.6095  -373.1618\n",
      "  434.6423   544.5986   193.8787   406.0195   275.0956   529.0730   338.7035\n",
      "\n",
      "Columns 7 to 7 \n",
      "  113.9521\n",
      " -119.8311\n",
      " -176.1768\n",
      "  -88.6769\n",
      "  338.6405\n",
      " -322.2929\n",
      "  230.2777\n",
      "   85.3622\n",
      " -184.2469\n",
      "  -22.9868\n",
      "  186.3902\n",
      " -199.3500\n",
      "  237.5882\n",
      "  292.1374\n",
      " -324.8597\n",
      "  423.0237\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1362  1383  1037  1181  1377  1334  1408  1344\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 6 \n",
      "  223.7102   493.6465    69.1472   426.1682   317.8879   216.8830   144.9226\n",
      " -530.6113  -847.1752  -221.3249  -708.5571  -662.4086  -395.0656  -327.9605\n",
      " -158.1644  -203.3969  -174.7579  -240.2498  -179.4408  -209.1711  -161.2839\n",
      " -143.4777  -471.3670   -89.6057  -557.6962  -226.8069  -280.6924  -138.9071\n",
      "  146.8673   413.2679   249.4859   658.3989    58.9866   370.7072   227.1812\n",
      " -433.7973  -718.2522  -323.3960  -735.7629  -510.9778  -483.0396  -407.6439\n",
      "  -78.3659  -347.1469   157.0500  -342.1836  -116.8344   -91.0569    16.9071\n",
      "  374.9130   705.5842   166.4355   755.7339   360.2033   336.9232   220.2588\n",
      " -269.7137  -810.3840   -95.7548  -847.0969  -319.7367  -396.9155  -193.3141\n",
      " -630.0992 -1343.4961  -188.2352 -1349.0851  -629.8612  -616.8756  -354.8504\n",
      "  142.0822   263.5036   227.0505   339.8256    99.3935   210.5456   186.0148\n",
      "  133.6955   256.3953  -135.4997   191.2909    74.7796     3.4833   -57.3646\n",
      "  156.8256   310.1202   240.2493   641.4503    68.8475   396.2140   259.3210\n",
      "  681.7217  1286.9987   324.4739  1361.6698   723.6629   743.2246   483.5689\n",
      " -235.1091  -634.8840  -232.6651  -834.6852  -216.0531  -484.2183  -284.9312\n",
      "  134.2693   335.1220   311.7776   630.2115   197.8797   374.5957   270.2881\n",
      "\n",
      "Columns 7 to 7 \n",
      "  125.5838\n",
      " -172.7956\n",
      " -270.2308\n",
      " -161.4559\n",
      "  508.2603\n",
      " -417.6425\n",
      "   91.9929\n",
      "  311.7745\n",
      " -332.6255\n",
      " -425.2567\n",
      "  343.0712\n",
      " -170.4438\n",
      "  418.2239\n",
      "  474.7224\n",
      " -349.5021\n",
      "  559.7814\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1372  1147  1393  1650  1432  1376  1398  1500\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 6 \n",
      "  130.3369   127.1259   334.8607   622.4116   141.8377   111.4093   577.6242\n",
      " -182.0934  -125.8857  -661.7751 -1190.0676  -203.6506  -115.8596  -910.8267\n",
      " -290.4387  -182.2387  -194.0659  -247.7031  -275.0068  -216.4525  -193.5961\n",
      " -195.1035  -126.4410  -185.2341  -322.0594  -217.3305  -137.4312  -487.5387\n",
      "  568.0551   316.6184  -122.8918  -136.6552   554.9558   390.8623   120.3771\n",
      " -463.5100  -359.0862  -513.1168  -731.3041  -447.4983  -361.0728  -669.6501\n",
      "    4.7940   253.4317    16.0920  -260.9674   -30.5920   248.5089  -307.1028\n",
      "  400.4631    20.6237   152.8754   389.9686   461.5215    40.2715   446.9203\n",
      " -392.2779  -141.2096  -195.1399  -562.7839  -410.6283  -227.9359  -682.0717\n",
      " -638.2151    69.8684  -217.6778  -696.7579  -706.1835    37.0936  -885.0123\n",
      "  388.9710   188.1539    27.9616   -60.1400   405.8992   177.8154    17.0255\n",
      " -109.7310  -248.5281  -184.8169  -183.3089   -69.4595  -277.0611    41.3883\n",
      "  477.3842   201.3299  -178.1639  -383.3843   486.7068   254.1116   100.3142\n",
      "  563.3865   230.8155   457.2163  1078.1136   626.1951   280.0422  1065.1665\n",
      " -379.4850  -306.3661   -67.4089  -275.5828  -380.6940  -399.4826  -476.2549\n",
      "  512.7786   460.9431   187.4863   194.4793   526.3671   545.4900   360.5390\n",
      "\n",
      "Columns 7 to 7 \n",
      "  163.0455\n",
      " -263.0464\n",
      " -199.8223\n",
      " -172.6976\n",
      "  416.1190\n",
      " -459.7656\n",
      "    8.5796\n",
      "  290.3206\n",
      " -346.1289\n",
      " -429.6833\n",
      "  234.2939\n",
      " -112.6674\n",
      "  305.5068\n",
      "  492.6653\n",
      " -335.6818\n",
      "  489.5674\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1380  1432   969   918  1428  1406  1424  1330\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 6 \n",
      "  542.9118   -29.4791   -46.1915   -21.8700   116.2457   127.2241    37.3037\n",
      "-1364.2397   332.9775   482.0118     6.0261  -172.8889  -411.3656  -182.2831\n",
      " -318.0205  -340.8150  -405.4179  -135.2424  -130.0610  -140.5992  -240.6965\n",
      " -257.3513  -255.5430  -300.9412   -84.3988  -125.0609   -84.2920  -171.5912\n",
      " -547.2145   717.6858   764.3064   297.8792    18.8134   -22.0046   412.8443\n",
      " -951.1542  -293.8371  -316.8067  -224.2512  -300.2674  -408.0559  -387.0871\n",
      "  -19.1978   341.6437   301.8171   206.5309    65.4768   107.6767    21.5093\n",
      "  246.9326  -133.1655  -243.1899    17.4780   -31.2307   118.4595   263.1435\n",
      "  -92.2156  -397.5249  -464.1915  -107.8398   -99.2001   -46.5058  -309.6908\n",
      " -260.9970   401.3900   433.1252    95.7235    72.6062  -147.4683  -390.5141\n",
      " -235.4612   110.4674    61.3553    67.4259   -34.3807    30.8356   249.7054\n",
      " -462.0836  -559.5552  -569.5385  -177.9236  -174.5662   -66.1420  -133.9678\n",
      " -565.9679   421.8452   429.1009   299.7267    11.6054   107.2286   460.6035\n",
      "  703.9691    98.9074    47.7082   106.7023    97.9679   283.1115   372.0943\n",
      "  166.8107  -664.3496  -778.5725  -253.1818   -94.5488   -56.0391  -340.3875\n",
      "  264.8806  1055.2062  1119.8792   438.9279   274.9109   220.5827   495.2963\n",
      "\n",
      "Columns 7 to 7 \n",
      "  145.1851\n",
      " -291.4880\n",
      " -132.4061\n",
      " -102.4797\n",
      "   23.0602\n",
      " -407.8279\n",
      "  123.1992\n",
      "   27.2611\n",
      "  -20.5123\n",
      "   -6.5645\n",
      "    0.6392\n",
      " -146.9740\n",
      "   84.0811\n",
      "  181.7407\n",
      "  -50.2594\n",
      "  285.5497\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1380  1488  1370  1408   819  1528  1302  1524\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 6 \n",
      "  794.1560   626.6431   329.4366   551.9875   481.4297   238.4146   734.8628\n",
      "-1791.4136 -1462.8397  -811.9195 -1289.8179 -1218.8330  -700.4697 -1842.4106\n",
      " -413.7971  -322.9226  -183.8474  -256.0562  -287.8412  -176.9943  -641.4381\n",
      " -401.9882  -293.1218  -173.7339  -241.5170  -233.2257  -125.7691  -506.5923\n",
      " -742.0574  -543.0013  -290.8957  -252.3754  -496.8612   -92.9867   518.8049\n",
      "-1205.3911  -968.5539  -556.4958  -839.5808  -845.2542  -473.4328 -1167.0121\n",
      " -120.1365  -110.2571   -26.7042  -164.9925    -5.2931   -10.8840  -435.1609\n",
      "  282.2216   283.8436   179.1141   409.4776   218.1795   270.9915  1161.6677\n",
      " -216.1451  -225.3320   -96.1274  -395.2409   -62.2343  -160.1582 -1121.1754\n",
      " -318.8391  -336.8775  -215.9744  -623.2911  -229.8051  -418.2408 -2184.4036\n",
      " -368.8328  -266.5177  -111.1278  -120.2341  -199.5558     9.1861   547.9695\n",
      " -708.9963  -516.4504  -205.7092  -223.1687  -393.6770   -25.4479   235.3762\n",
      " -796.1760  -630.0435  -316.0791  -396.9727  -512.3178   -77.4935   227.8596\n",
      "  910.4822   841.3754   462.6133  1028.8379   628.5232   589.9830  2443.1426\n",
      "  251.6303   104.5856    64.0336  -178.9451   155.8992  -100.9812  -963.3815\n",
      "  315.4350   226.9137   155.8199   120.9100   242.6171   112.3771    82.5109\n",
      "\n",
      "Columns 7 to 7 \n",
      "  692.6896\n",
      "-1811.6637\n",
      " -555.9929\n",
      " -477.1739\n",
      "  329.8929\n",
      "-1057.8846\n",
      " -396.9218\n",
      " 1067.8715\n",
      "-1003.7879\n",
      "-1961.4276\n",
      "  325.2369\n",
      "  223.4254\n",
      "  112.3467\n",
      " 2256.9189\n",
      " -826.0892\n",
      "   -6.4070\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1336  1070   893  1029  1302  1135  1556  1490\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 6 \n",
      "  127.9580   647.8974   537.5525   946.3707   486.1641   491.1228   112.4231\n",
      " -305.8639 -1557.1929 -1294.1603 -2282.4382 -1228.8901 -1190.1432   -21.1196\n",
      " -109.7296  -432.3319  -290.0091  -750.1492  -500.5175  -512.6061  -231.9941\n",
      "  -73.3018  -383.1099  -265.3081  -659.4152  -355.4907  -388.8627  -227.7893\n",
      "  107.4589   224.0513  -523.8996   610.5507   518.8193   515.6212   193.0564\n",
      " -317.8234  -963.7148  -887.6781 -1351.0455  -890.5738  -870.7595  -461.9008\n",
      "   48.0425  -323.4118   -48.4876  -604.9414  -258.6388  -265.9530   170.1458\n",
      "  164.7697   839.9487   233.7335  1402.2013   884.9296   870.7650  -171.2428\n",
      " -132.8418  -836.0605  -113.7106 -1458.6056  -808.4009  -801.9123  -152.7839\n",
      " -252.9307 -1552.6034  -262.2472 -2702.1089 -1678.3195 -1695.1082   245.7880\n",
      "   92.7372   198.4758  -228.4109   597.1486   530.8940   556.8627   -55.1297\n",
      "   -8.9973   139.0949  -426.2991   292.9703   233.5901   247.0810  -295.1120\n",
      "  138.4000    13.6268  -560.5582   215.4206   392.5605   430.8856   125.0044\n",
      "  336.3962  1833.8425   684.6110  2990.0210  1775.2780  1763.7533   -11.6177\n",
      " -160.2726  -658.6205   158.3646 -1209.6537  -747.0103  -757.3916  -223.0305\n",
      "  124.6039   -22.4041   237.6734   -63.4576   141.3281   118.1831   590.1949\n",
      "\n",
      "Columns 7 to 7 \n",
      "   39.9745\n",
      " -229.2932\n",
      " -171.2189\n",
      "  -85.7873\n",
      "  230.8937\n",
      " -306.6047\n",
      "  129.3243\n",
      "  140.7809\n",
      " -165.9388\n",
      " -141.1627\n",
      "   94.5812\n",
      "  -92.2226\n",
      "  232.3488\n",
      "  331.7143\n",
      " -254.5057\n",
      "  326.8167\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1025  1288  1226  1364  1480  1444  1492  1362\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 6 \n",
      "  409.8885   -58.4113   409.0117    16.3396   -41.8094   726.4454   406.4942\n",
      " -986.0682   580.6042 -1106.0848   -91.4520    60.9106 -1659.5840 -1080.9265\n",
      " -479.0856  -428.8036  -272.7285  -249.7414  -271.0149  -376.3073  -278.1386\n",
      " -372.1350  -318.0118  -220.8377  -146.9681  -167.0764  -344.5283  -222.1935\n",
      "  518.1584   803.1396  -455.7648   401.8170   528.4015  -627.6875  -199.9095\n",
      " -792.9358  -329.2157  -809.7116  -342.2945  -300.0731 -1120.9022  -712.2291\n",
      " -229.7734   285.4996    64.0228   126.1029   182.7317  -133.5630   -65.7971\n",
      "  773.2845  -305.7091   193.1062   132.2067   102.8357   276.4409   360.9256\n",
      " -716.2107  -524.8186    17.9886  -309.1823  -289.4514  -216.4376  -247.8961\n",
      "-1521.1831   483.4915  -188.3476  -109.8422   -62.2967  -338.2748  -523.4120\n",
      "  567.9578    -4.0587  -177.2604   139.3783   198.4813  -335.7909   -51.7378\n",
      "  212.1375  -624.5659  -321.1289  -248.6761  -306.7728  -653.3312  -152.4641\n",
      "  498.1823   490.2642  -440.2462   332.8492   467.0644  -726.6793  -209.4989\n",
      " 1527.4441    14.4433   502.5943   248.0147   161.0472   927.1790   864.1482\n",
      " -690.3048  -842.6507   185.7599  -349.1315  -402.6957   137.0559  -108.2373\n",
      "  170.9551  1228.4427   294.1671   599.5618   690.7944   263.5023   183.3749\n",
      "\n",
      "Columns 7 to 7 \n",
      "  732.3349\n",
      "-1860.4080\n",
      " -743.3846\n",
      " -554.0665\n",
      "  748.8090\n",
      "-1162.9329\n",
      " -462.1001\n",
      " 1327.0844\n",
      "-1254.6703\n",
      "-2551.5361\n",
      "  753.2686\n",
      "  383.6724\n",
      "  481.7383\n",
      " 2711.6062\n",
      "-1157.4037\n",
      "   -0.6642\n",
      "[torch.cuda.FloatTensor of size 16x8 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1434  1495  1542  1325  1401  1068  1370  1544\n",
      "[torch.cuda.FloatTensor of size 1x8 (GPU 0)]\n",
      "\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "torch.Size([16, 8])\n",
      "torch.Size([1, 8])\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n",
      "img <class 'torch.FloatTensor'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a0d0490c58b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m         disc_loss = criterion_disc(ins_predict,\n\u001b[0;32m     51\u001b[0m                                    \u001b[0mins_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                                    [n_sticks] * len(images))\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdisc_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mdisc_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch0.3.1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\ykato_git\\omg_instance_segmentation\\src\\pytorch-discriminative-loss-master\\src\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target, n_clusters)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_discriminative_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_discriminative_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\ykato_git\\omg_instance_segmentation\\src\\pytorch-discriminative-loss-master\\src\\loss.py\u001b[0m in \u001b[0;36m_discriminative_loss\u001b[1;34m(self, input, target, n_clusters)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_n_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mc_means\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cluster_means\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0ml_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variance_term\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_means\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0ml_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distance_term\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_means\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\ykato_git\\omg_instance_segmentation\\src\\pytorch-discriminative-loss-master\\src\\loss.py\u001b[0m in \u001b[0;36m_cluster_means\u001b[1;34m(self, input, target, n_clusters)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mmean_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtarget_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch0.3.1\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'Variable containing:'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch0.3.1\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch0.3.1\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;31m# characters to replace unicode characters with.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch0.3.1\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mstrt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_vector_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[0mstrt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_matrix_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[0mstrt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch0.3.1\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_matrix_str\u001b[1;34m(self, indent, formatter, force_truncate)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformatter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         fmt, scale, sz = _number_format(self,\n\u001b[1;32m--> 216\u001b[1;33m                                         min_sz=5 if not print_full_mat else 0)\n\u001b[0m\u001b[0;32m    217\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch0.3.1\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_number_format\u001b[1;34m(tensor, min_sz)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0m_min_log_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_min_log_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mmin_sz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_sz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDoubleTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mpos_inf_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model_dir = Path('../model')\n",
    "\n",
    "best_loss = np.inf\n",
    "for epoch in range(300):\n",
    "    print(f'epoch : {epoch}')\n",
    "    disc_losses = []\n",
    "    ce_losses = []\n",
    "    for batched in train_dataloader:\n",
    "        images, sem_labels, ins_labels = batched\n",
    "        \n",
    "        nb ,nc, nh, nw = sem_labels.size()\n",
    "        \n",
    "#         print('images ', images.numpy().shape)\n",
    "#         print('sem_labels ', sem_labels.numpy().shape)\n",
    "#         print('ins_labels ', ins_labels.numpy().shape)\n",
    "#         save_image(images,'debug_images.png', padding=10)\n",
    "# #         save_image(torch.from_numpy(sem_labels.numpy()[:,0,:,:]).contiguous(),'debug_sem_labels.png', padding=10)\n",
    "# #         save_image(ins_labels,'debug_ins_labels.png', padding=10)\n",
    "#         print(type(sem_labels), sem_labels.size())\n",
    "#         tmpTensor = sem_labels[:,0,:,:].contiguous()\n",
    "#         save_image(tmpTensor.view(nb, 1, nh, nw),'debug_sem_labels.png', padding=10)\n",
    "#         for i in range(8):\n",
    "#             tmpTensor = ins_labels[:,i,:,:].contiguous()\n",
    "#             save_image(tmpTensor.view(nb, 1, nh, nw),'debug_ins_labels{}.png'.format(i), padding=10)\n",
    "        \n",
    "        \n",
    "        images = Variable(images).cuda()\n",
    "        sem_labels = Variable(sem_labels).cuda()\n",
    "        ins_labels = Variable(ins_labels).cuda()\n",
    "        model.zero_grad()\n",
    "\n",
    "        sem_predict, ins_predict = model(images)\n",
    "        loss = 0\n",
    "        \n",
    "#         print('sem_predict ', sem_predict.cpu().data.numpy().shape)\n",
    "#         #save_image(sem_predict[:,0,:,:],'debug_sem_predict.png', padding=10)\n",
    "#         tmpTensor = sem_predict.cpu().data\n",
    "#         print(type(tmpTensor), tmpTensor.size())\n",
    "#         tmpTensor = tmpTensor[:,0,:,:].contiguous()\n",
    "#         save_image(tmpTensor.view(nb, 1, nh, nw),'debug_sem_predict.png', padding=10)\n",
    "#         tmpTensor = ins_predict.cpu().data\n",
    "#         print(type(tmpTensor), tmpTensor.size())\n",
    "#         for i in range(16):\n",
    "#             tmpTensor_a = tmpTensor[:,i,:,:].contiguous()\n",
    "#             print('ins_predict', tmpTensor_a.view(nb, 1, nh, nw).size())\n",
    "#             save_image(tmpTensor_a.view(nb, 1, nh, nw),'debug_ins_predict{}.png'.format(i), padding=10)\n",
    "\n",
    "        # Discriminative Loss\n",
    "        disc_loss = criterion_disc(ins_predict,\n",
    "                                   ins_labels,\n",
    "                                   [n_sticks] * len(images))\n",
    "        loss += disc_loss\n",
    "        disc_losses.append(disc_loss.cpu().data.numpy()[0])\n",
    "\n",
    "        # Cross Entropy Loss\n",
    "        _, sem_labels_ce = sem_labels.max(1)\n",
    "        ce_loss = criterion_ce(sem_predict.permute(0, 2, 3, 1)\\\n",
    "                                   .contiguous().view(-1, 2),\n",
    "                               sem_labels_ce.view(-1))\n",
    "        loss += ce_loss\n",
    "        ce_losses.append(ce_loss.cpu().data.numpy()[0])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    disc_loss = np.mean(disc_losses)\n",
    "    ce_loss = np.mean(ce_losses)\n",
    "    print(f'DiscriminativeLoss: {disc_loss:.4f}')\n",
    "    print(f'CrossEntropyLoss: {ce_loss:.4f}')\n",
    "    scheduler.step(disc_loss)\n",
    "    if disc_loss < best_loss:\n",
    "        best_loss = disc_loss\n",
    "        print('Best Model!')\n",
    "        modelname = 'model.pth'\n",
    "        torch.save(model.state_dict(), model_dir.joinpath(modelname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-pytorch0.3.1",
   "language": "python",
   "name": "pytorch0.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
